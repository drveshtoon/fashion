# -*- coding: utf-8 -*-
"""batch processing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vsN3UPtO0-DCwePHJyskNt1F7vW5GH09
"""

import zipfile
import os

# Unzipping the archive file
with zipfile.ZipFile('/content/archive (2).zip', 'r') as zip_ref:
    zip_ref.extractall('fashion_data')  # Extract into a folder named 'fashion_data'

# Check the contents of the extracted folder
os.listdir('fashion_data')

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()

# Step 3: Preprocess the data
# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# Reshape the data to add the channel dimension (28, 28, 1) for grayscale images
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)
test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10) # 10 classes for 10 clothing types
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=10,
          validation_data=(test_images, test_labels))

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

print('\nTest accuracy:', test_acc)

model.save("fashion_mnist_model.h5")

!pip install fastapi
!pip install uvicorn
!pip install python-multipart

from fastapi import FastAPI, File, UploadFile
import tensorflow as tf
from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image
import io

# Initialize FastAPI app
app = FastAPI()

# Load the trained model
model = load_model('fashion_mnist_model.h5')

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    # Read the image file
    contents = await file.read()
    img = Image.open(io.BytesIO(contents)).convert('L')  # For grayscale (adjust based on your model)
    img = img.resize((28, 28))  # Resize to the model input size (based on Fashion MNIST dataset)
    img = np.array(img)
    img = img.reshape(1, 28, 28, 1)  # Add batch dimension for prediction

    # Normalize the image as your model was trained on normalized data
    img = img / 255.0

    # Make the prediction
    prediction = model.predict(img)

    # Convert prediction to a list of probabilities (or class labels)
    prediction_probabilities = prediction[0].tolist()

    # Return the prediction
    return {"prediction": prediction_probabilities}

# To run this app, use the command below:
# uvicorn app:app --reload

import zipfile
import os

# Path to the zip file
zip_file_path = '/content/archive (3).zip'

# Extract the zip file to a directory
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall('new_images')  # Extract to 'new_images' folder

# Check the contents of the extracted folder
os.listdir('new_images')

# Path to the folder containing new images to classify
image_folder = 'new_images'

import requests
import os

# URL of the FastAPI prediction endpoint
API_URL = "http://localhost:8000/predict/"

# Path to the folder containing new images to classify
image_folder = "new_images"

def batch_predict():
    image_files = [f for f in os.listdir(image_folder) if f.endswith('.png') or f.endswith('.jpg')]

    # Read images and send them to the FastAPI service in batches
    for img in image_files:
        file_path = os.path.join(image_folder, img)
        with open(file_path, 'rb') as f:
            files = {'file': f}
            response = requests.post(API_URL, files=files)

            if response.status_code == 200:
                prediction = response.json()
                print(f"Prediction for {img}: {prediction}")
            else:
                print(f"Failed to get prediction for {img}. Status code:", response.status_code)

# Run the batch prediction function
batch_predict()

